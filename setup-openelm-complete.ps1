# ğŸŒŸ OpenELM 1.1B Complete Setup Script
# Sets up Buddy AI with OpenELM 1.1B and Ultimate Personalization

$ErrorActionPreference = "Stop"

Write-Host "ğŸŒŸ OpenELM 1.1B Ultimate Setup" -ForegroundColor Cyan
Write-Host "===============================" -ForegroundColor Cyan
Write-Host ""

function Write-Progress-Step {
    param($Step, $Total, $Message)
    Write-Host "[$Step/$Total] $Message" -ForegroundColor Yellow
}

function Write-Success {
    param($Message)
    Write-Host "âœ… $Message" -ForegroundColor Green
}

function Write-Error-Message {
    param($Message)
    Write-Host "âŒ $Message" -ForegroundColor Red
}

try {
    $TotalSteps = 6
    $CurrentStep = 0

    # Step 1: Start Ollama service
    $CurrentStep++
    Write-Progress-Step $CurrentStep $TotalSteps "Starting Ollama service..."
    
    Start-Process "ollama" "serve" -WindowStyle Hidden -ErrorAction SilentlyContinue
    Start-Sleep -Seconds 5
    Write-Success "Ollama service started"

    # Step 2: Pull OpenELM model
    $CurrentStep++
    Write-Progress-Step $CurrentStep $TotalSteps "Downloading OpenELM 1.1B model..."
    Write-Host "  Model size: ~1.3GB (much smaller than Llama!)" -ForegroundColor Green
    Write-Host "  This should take 2-5 minutes depending on your connection..."
    
    ollama pull openelm:1.1b-instruct
    Write-Success "OpenELM 1.1B downloaded successfully"

    # Step 3: Create custom model with enhanced prompt
    $CurrentStep++
    Write-Progress-Step $CurrentStep $TotalSteps "Creating custom Buddy AI model..."
    
    if (Test-Path "Modelfile.openelm") {
        ollama create buddy-ai-openelm -f Modelfile.openelm
        Write-Success "Custom Buddy AI model created with ultimate personalization"
    } else {
        Write-Error-Message "Modelfile.openelm not found"
        exit 1
    }

    # Step 4: Setup Python environment
    $CurrentStep++
    Write-Progress-Step $CurrentStep $TotalSteps "Setting up Python environment..."
    
    if (-not (Test-Path "venv")) {
        python -m venv venv
    }
    
    & ".\venv\Scripts\Activate.ps1"
    python -m pip install --upgrade pip
    
    # Install enhanced dependencies for OpenELM
    pip install fastapi uvicorn python-multipart requests transformers torch torchvision torchaudio accelerate tokenizers safetensors
    
    Write-Success "Python environment ready"

    # Step 5: Setup frontend
    $CurrentStep++
    Write-Progress-Step $CurrentStep $TotalSteps "Setting up frontend..."
    
    if (Test-Path "package.json") {
        npm install
        Write-Success "Frontend dependencies installed"
    }

    # Step 6: Create enhanced test script
    $CurrentStep++
    Write-Progress-Step $CurrentStep $TotalSteps "Creating test scripts..."

    # Create advanced test script
    @"
#!/usr/bin/env python3
"""
Enhanced OpenELM 1.1B Test Script - Ultimate Personalization Demo
"""
import subprocess
import time
import json
import sys

def test_model(prompt, expected_features=None):
    """Test the model with a specific prompt"""
    print(f"\nğŸ” Testing: {prompt[:50]}...")
    
    try:
        # Test via Ollama CLI
        result = subprocess.run(
            ['ollama', 'run', 'buddy-ai-openelm', prompt],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            response = result.stdout.strip()
            print(f"âœ… Response: {response[:200]}...")
            
            if expected_features:
                for feature in expected_features:
                    if feature.lower() in response.lower():
                        print(f"   âœ… Found: {feature}")
                    else:
                        print(f"   âš ï¸  Missing: {feature}")
            return True
        else:
            print(f"âŒ Error: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ Response timed out")
        return False
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        return False

def main():
    print("ğŸ§ª OpenELM 1.1B Ultimate Personalization Test")
    print("=" * 50)
    
    # Test scenarios with expected personalization features
    tests = [
        {
            "prompt": "Hi! I'm feeling excited about starting a new project today. What should I focus on?",
            "features": ["excited", "energy", "project", "focus"]
        },
        {
            "prompt": "I'm stressed about an upcoming presentation. I mentioned this worry before.",
            "features": ["stressed", "presentation", "remember", "support"]
        },
        {
            "prompt": "Can you solve this math problem: 2x + 8 = 20? I usually struggle with algebra.",
            "features": ["step-by-step", "algebra", "struggle", "x = 6"]
        },
        {
            "prompt": "I love photography and travel. What's a good destination for landscape photos?",
            "features": ["photography", "travel", "landscape", "recommendation"]
        }
    ]
    
    passed = 0
    total = len(tests)
    
    for i, test in enumerate(tests, 1):
        print(f"\n--- Test {i}/{total} ---")
        if test_model(test["prompt"], test["features"]):
            passed += 1
        time.sleep(2)  # Brief pause between tests
    
    print(f"\nğŸ¯ Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ Perfect! Your OpenELM 1.1B model is working beautifully!")
        print("\nğŸš€ Ready to use:")
        print("   - Emotional intelligence âœ…")
        print("   - Memory & personalization âœ…") 
        print("   - Context awareness âœ…")
        print("   - Adaptive responses âœ…")
    else:
        print("âš ï¸  Some tests failed. The model is working but may need fine-tuning.")
    
    print(f"\nğŸ’¡ To chat directly: ollama run buddy-ai-openelm")

if __name__ == "__main__":
    main()
"@ | Out-File -FilePath "test_openelm_ultimate.py" -Encoding UTF8

    Write-Success "Advanced test script created"

    # Create quick start script
    @"
# ğŸš€ Quick Start - OpenELM Buddy AI
Write-Host "ğŸŒŸ Starting OpenELM 1.1B Buddy AI..." -ForegroundColor Cyan

# Start Ollama service
Start-Process "ollama" "serve" -WindowStyle Hidden -ErrorAction SilentlyContinue
Start-Sleep -Seconds 3

Write-Host "âœ… Ollama running"
Write-Host ""
Write-Host "ğŸ¯ Available commands:" -ForegroundColor Yellow
Write-Host "  Chat directly:    ollama run buddy-ai-openelm"
Write-Host "  Run tests:        python test_openelm_ultimate.py"
Write-Host "  Start web app:    python backend/main.py"
Write-Host ""
Write-Host "ğŸ’¡ Try saying: 'Hi! I'm excited about learning AI. What should I start with?'"
Write-Host ""
"@ | Out-File -FilePath "start-openelm.ps1" -Encoding UTF8

    # Success message
    Write-Host ""
    Write-Host "ğŸ‰ OpenELM 1.1B Setup Complete!" -ForegroundColor Green
    Write-Host "================================" -ForegroundColor Green
    Write-Host ""
    Write-Host "ğŸŒŸ What you now have:" -ForegroundColor Cyan
    Write-Host "  âœ… OpenELM 1.1B model (1.3GB only!)"
    Write-Host "  âœ… Ultimate personalization prompt"
    Write-Host "  âœ… Advanced emotional intelligence"
    Write-Host "  âœ… Memory & learning capabilities"
    Write-Host "  âœ… Context-aware responses"
    Write-Host ""
    Write-Host "ğŸš€ Quick Start:" -ForegroundColor Yellow
    Write-Host "  Test it:     python test_openelm_ultimate.py"
    Write-Host "  Chat now:    ollama run buddy-ai-openelm"
    Write-Host "  Web app:     python backend/main.py"
    Write-Host ""
    Write-Host "ğŸ’¡ Model Features:" -ForegroundColor Green
    Write-Host "  - Remembers your preferences & history"
    Write-Host "  - Adapts to your communication style" 
    Write-Host "  - Provides emotional support"
    Write-Host "  - Makes personalized recommendations"
    Write-Host "  - Learns from every conversation"
    Write-Host ""
    Write-Host "ğŸ¯ Your AI companion is ready to learn about you!" -ForegroundColor Magenta

} catch {
    Write-Error-Message "Setup failed: $_"
    Write-Host ""
    Write-Host "ğŸ”§ Common fixes:" -ForegroundColor Yellow
    Write-Host "  1. Make sure Ollama is installed"
    Write-Host "  2. Check your internet connection"
    Write-Host "  3. Ensure you have enough disk space (2GB+)"
    Write-Host "  4. Try running as administrator"
    exit 1
}